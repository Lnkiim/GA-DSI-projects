{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "* this notebook has unbalanced data\n",
    "* null values were dropped- performed better than dataset with imputed values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellenkim/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ellenkim/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sqlalchemy import create_engine\n",
    "import pickle \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('drop_wt_trans.pkl', 'r') as picklefile:\n",
    "    df5 = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>VehOdo</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>WarrantyCost</th>\n",
       "      <th>ADESA</th>\n",
       "      <th>MANHEIM</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>OK</th>\n",
       "      <th>OR</th>\n",
       "      <th>PA</th>\n",
       "      <th>SC</th>\n",
       "      <th>TN</th>\n",
       "      <th>TX</th>\n",
       "      <th>UT</th>\n",
       "      <th>VA</th>\n",
       "      <th>WA</th>\n",
       "      <th>WV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.758303</td>\n",
       "      <td>0.296750</td>\n",
       "      <td>0.092524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.799509</td>\n",
       "      <td>0.291044</td>\n",
       "      <td>0.083997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.620205</td>\n",
       "      <td>0.182856</td>\n",
       "      <td>0.131751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.545986</td>\n",
       "      <td>0.111950</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.579969</td>\n",
       "      <td>0.172441</td>\n",
       "      <td>0.079306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsBadBuy    VehOdo  MMRCurrentRetailAveragePrice  WarrantyCost  ADESA  \\\n",
       "0         0  0.758303                      0.296750      0.092524    1.0   \n",
       "1         0  0.799509                      0.291044      0.083997    1.0   \n",
       "2         0  0.620205                      0.182856      0.131751    1.0   \n",
       "3         0  0.545986                      0.111950      0.023877    1.0   \n",
       "4         0  0.579969                      0.172441      0.079306    1.0   \n",
       "\n",
       "   MANHEIM  OTHER    1   10   11 ...    OK   OR   PA   SC   TN   TX   UT   VA  \\\n",
       "0      0.0    0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.0    0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.0    0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.0    0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.0    0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    WA   WV  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 353 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df5.drop(['IsBadBuy'], 1)\n",
    "y= df5[\"IsBadBuy\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample= df5.ix[13298,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellenkim/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 354 and input n_features is 355 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-791787e45e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ellenkim/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ellenkim/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 354 and input n_features is 355 "
     ]
    }
   ],
   "source": [
    "dt_predictions = dtree.predict(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: DECISION TREE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "dt_predictions = dtree.predict(X_test)\n",
    "dt_proba = dtree.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.90      0.91     18856\n",
      "          1       0.14      0.15      0.14      1993\n",
      "\n",
      "avg / total       0.84      0.83      0.83     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test,dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17039  1817]\n",
      " [ 1704   289]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=200, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.87615021628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "dt_PARAMETERS = {\"max_depth\":[1,2,3,4,5,7,9,10,15,20,30], \"max_features\": [1,10,30,100,200,300]}\n",
    "dt_SCORING = \"accuracy\"\n",
    "dt_model = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(dt_model, param_grid=dt_PARAMETERS, scoring=dt_SCORING)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#look at max features\n",
    "\n",
    "print grid.best_estimator_\n",
    "print grid.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuned Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=3)\n",
    "dtree.fit(X_train,y_train)\n",
    "dt_predictions = dtree.predict(X_test)\n",
    "dt_proba = dtree.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Not_Lemon  Lemon  thresh50  thresh10  thresh08\n",
      "0        1.0    0.0         0         0         0\n",
      "1        1.0    0.0         0         0         0\n",
      "2        1.0    0.0         0         0         0\n",
      "3        1.0    0.0         0         0         0\n",
      "4        1.0    0.0         0         0         0\n",
      "5        1.0    0.0         0         0         0\n",
      "6        1.0    0.0         0         0         0\n",
      "7        1.0    0.0         0         0         0\n",
      "8        1.0    0.0         0         0         0\n",
      "9        1.0    0.0         0         0         0\n"
     ]
    }
   ],
   "source": [
    "dt_y_pp = pd.DataFrame(dtree.predict_proba(X_test), columns=['Not_Lemon','Lemon'])\n",
    "\n",
    "dt_y_pp['thresh50'] = dt_predictions\n",
    "dt_y_pp['thresh10'] = [1 if x >= 0.1 else 0 for x in dt_y_pp.Lemon.values]\n",
    "dt_y_pp['thresh08'] = [1 if x >= 0.08 else 0 for x in dt_y_pp.Lemon.values]\n",
    "print(dt_y_pp.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Threshold (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - 50% Threshold\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.90      0.91     18856\n",
      "          1       0.14      0.15      0.14      1993\n",
      "\n",
      "avg / total       0.84      0.83      0.83     20849\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for 50% threshold\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon             289            1704\n",
      "Not_Lemon        1817           17039 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Classification Report - 50% Threshold\"\"\\n\"\n",
    "print(classification_report(y_test,dt_predictions))\n",
    "\n",
    "dt_conmat_50 = np.array(confusion_matrix(y_test, dt_y_pp.thresh50.values, labels=[1,0]))\n",
    "dt_confusion_50 = pd.DataFrame(dt_conmat_50, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "\n",
    "print \"\\n\" \"\\n\" \"\\n\" \"Confusion Matrix for 50% threshold\" \n",
    "print str(dt_confusion_50), \"\\n\" \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classication Report 10% Threshold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.58      0.71     18856\n",
      "          1       0.13      0.60      0.21      1993\n",
      "\n",
      "avg / total       0.86      0.58      0.66     20849\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for 10% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon            1200             793\n",
      "Not_Lemon        8004           10852 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Classication Report 10% Threshold\"\n",
    "dt_pred10 = dt_y_pp['thresh10']\n",
    "print(classification_report(y_test,dt_pred10))\n",
    "\n",
    "dt_conmat_10 = np.array(confusion_matrix(y_test, dt_y_pp.thresh10.values, labels=[1,0]))\n",
    "dt_confusion_10 = pd.DataFrame(dt_conmat_10, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "print \"\\n\" \"\\n\" \"Confusion Matrix for 10% threshold\" \"\\n\"\n",
    "print str(dt_confusion_10), \"\\n\" \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8% Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classication Report 8% Threshold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.58      0.71     18856\n",
      "          1       0.13      0.60      0.21      1993\n",
      "\n",
      "avg / total       0.86      0.58      0.66     20849\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix for 8% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon            1200             793\n",
      "Not_Lemon        8004           10852 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Classication Report 8% Threshold\" \n",
    "dt_pred08 = dt_y_pp['thresh08']\n",
    "print(classification_report(y_test,dt_pred08))\n",
    "\n",
    "\n",
    "dt_conmat_08 = np.array(confusion_matrix(y_test, dt_y_pp.thresh08.values, labels=[1,0]))\n",
    "dt_confusion_08 = pd.DataFrame(dt_conmat_08, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "print \"\\n\" \"\\n\" \"Confusion Matrix for 8% threshold\" \"\\n\"\n",
    "print str(dt_confusion_08), \"\\n\" \"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2:  RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95     18856\n",
      "          1       0.33      0.02      0.04      1993\n",
      "\n",
      "avg / total       0.85      0.90      0.86     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rfc.predict(X_test)\n",
    "rf_proba = rfc.predict_proba(X_test)\n",
    "print(classification_report(y_test,rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "0.876405819898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "rf_PARAMETERS = {\"max_depth\":[1,2,3,4,5,7,9,10,15,20,30], \"n_estimators\": [10,20,50,100,200]}\n",
    "rf_SCORING = \"accuracy\"\n",
    "rf_model = RandomForestClassifier()\n",
    "grid = GridSearchCV(rf_model, param_grid=rf_PARAMETERS, scoring=rf_SCORING)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#look at max features\n",
    "\n",
    "print grid.best_estimator_\n",
    "print grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rfc = RandomForestClassifier(max_depth=30, n_estimators=50)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     18856\n",
      "          1       0.50      0.00      0.01      1993\n",
      "\n",
      "avg / total       0.87      0.90      0.86     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rfc.predict(X_test)\n",
    "rf_proba = rfc.predict_proba(X_test)\n",
    "print(classification_report(y_test,rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold - 50%, 10%, 8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Not_Lemon     Lemon  thresh50  thresh10  thresh08\n",
      "0   0.919955  0.080045         0         0         1\n",
      "1   0.974154  0.025846         0         0         0\n",
      "2   0.928525  0.071475         0         0         0\n",
      "3   0.939960  0.060040         0         0         0\n",
      "4   0.805674  0.194326         0         1         1\n",
      "5   0.942848  0.057152         0         0         0\n",
      "6   0.922058  0.077942         0         0         0\n",
      "7   0.862430  0.137570         0         1         1\n",
      "8   0.932684  0.067316         0         0         0\n",
      "9   0.956405  0.043595         0         0         0\n"
     ]
    }
   ],
   "source": [
    "rf_Y_pp = pd.DataFrame(rfc.predict_proba(X_test), columns=['Not_Lemon','Lemon'])\n",
    "rf_Y_pp['thresh50'] = rf_predictions\n",
    "rf_Y_pp['thresh10'] = [1 if x >= 0.1 else 0 for x in rf_Y_pp.Lemon.values]\n",
    "rf_Y_pp['thresh08'] = [1 if x >= 0.08 else 0 for x in rf_Y_pp.Lemon.values]\n",
    "print(rf_Y_pp.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for 50% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon               8            1985\n",
      "Not_Lemon           8           18848 \n",
      "\n",
      "\n",
      "50% (default) THRESHOLD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     18856\n",
      "          1       0.50      0.00      0.01      1993\n",
      "\n",
      "avg / total       0.87      0.90      0.86     20849\n",
      "\n",
      "The accuracy score for threshold of 50% = 0.90440788527\n"
     ]
    }
   ],
   "source": [
    "rf_pred50 = rf_Y_pp['thresh50']\n",
    "rf_pred10 = rf_Y_pp['thresh10']\n",
    "rf_pred08 = rf_Y_pp['thresh08']\n",
    "\n",
    "rf_acc_50 = accuracy_score(y_test, rf_Y_pp[\"thresh50\"])\n",
    "rf_acc_10 = accuracy_score(y_test, rf_Y_pp[\"thresh10\"])\n",
    "rf_acc_08 =accuracy_score(y_test, rf_Y_pp[\"thresh08\"])\n",
    "\n",
    "rf_conmat_50 = np.array(confusion_matrix(y_test, rf_Y_pp.thresh50.values, labels=[1,0]))\n",
    "rf_confusion_50 = pd.DataFrame(rf_conmat_50, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "print \"Confusion Matrix for 50% threshold\" \"\\n\"\n",
    "print str(rf_confusion_50), \"\\n\" \"\\n\"\n",
    "print \"50% (default) THRESHOLD\"\n",
    "print(classification_report(y_test,rf_pred50))\n",
    "print \"The accuracy score for threshold of 50% =\", str(rf_acc_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for 10% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon            1194             799\n",
      "Not_Lemon        6466           12390 \n",
      "\n",
      "\n",
      "10% THRESHOLD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.66      0.77     18856\n",
      "          1       0.16      0.60      0.25      1993\n",
      "\n",
      "avg / total       0.86      0.65      0.72     20849\n",
      "\n",
      "The accuracy score for threshold of 10% = 0.651542040386\n"
     ]
    }
   ],
   "source": [
    "rf_conmat_10 = np.array(confusion_matrix(y_test, rf_Y_pp.thresh10.values, labels=[1,0]))\n",
    "rf_confusion_10 = pd.DataFrame(rf_conmat_10, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "print \"Confusion Matrix for 10% threshold\" \"\\n\"\n",
    "print str(rf_confusion_10), \"\\n\" \"\\n\"\n",
    "\n",
    "print \"10% THRESHOLD\"\n",
    "print(classification_report(y_test,rf_pred10))\n",
    "\n",
    "print \"The accuracy score for threshold of 10% =\", str(rf_acc_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8% Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for 8% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon            1447             546\n",
      "Not_Lemon        9038            9818 \n",
      "\n",
      "\n",
      "8% THRESHOLD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.52      0.67     18856\n",
      "          1       0.14      0.73      0.23      1993\n",
      "\n",
      "avg / total       0.87      0.54      0.63     20849\n",
      "\n",
      "The accuracy score for threshold of 8% = 0.54031368411\n"
     ]
    }
   ],
   "source": [
    "rf_conmat_08 = np.array(confusion_matrix(y_test, rf_Y_pp.thresh08.values, labels=[1,0]))\n",
    "rf_confusion_08 = pd.DataFrame(rf_conmat_08, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "print \"Confusion Matrix for 8% threshold\" \"\\n\"\n",
    "print str(rf_confusion_08), \"\\n\" \"\\n\"\n",
    "\n",
    "print \"8% THRESHOLD\"\n",
    "print(classification_report(y_test,rf_pred08))\n",
    "\n",
    "print \"The accuracy score for threshold of 8% =\", str(rf_acc_08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90114397  0.90062594  0.90135555]\n"
     ]
    }
   ],
   "source": [
    "# read default behavior\n",
    "rfc = RandomForestClassifier()\n",
    "print(cross_val_score(rfc, X, y))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# coefficients:\n",
    "logreg.coef_\n",
    "\n",
    "# predict class:\n",
    "lr_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# predicted probability:\n",
    "lr_y_pp = pd.DataFrame(logreg.predict_proba(X_test), columns=[\"Not_Lemons\",\"Lemons\"])\n",
    "#output is probabiliyt for every y_pred. what \n",
    "\n",
    "lr_y_pp['thresh50'] = lr_y_pred\n",
    "lr_y_pp.head()\n",
    "\n",
    "y_score = lr_y_pp[\"Lemons\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     18856\n",
      "          1       0.22      0.00      0.00      1993\n",
      "\n",
      "avg / total       0.84      0.90      0.86     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,lr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69415541369762346"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, y_score)\n",
    "auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellenkim/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.384256975137\n"
     ]
    }
   ],
   "source": [
    "dt_PARAMETERS = {\"penalty\":[\"l1\",\"l2\"], \"C\":[0.1,.5,1,] }\n",
    "dt_SCORING = 'precision'\n",
    "dt_model = LogisticRegression()\n",
    "grid = GridSearchCV(dt_model, param_grid=dt_PARAMETERS, scoring=dt_SCORING)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#look at max features\n",
    "\n",
    "print grid.best_estimator_\n",
    "print grid.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning Model 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, penalty=\"l1\")\n",
    "logreg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('logistic_reg.pkl', 'w') as picklefile:\n",
    "    pickle.dump(logreg, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not_Lemons</th>\n",
       "      <th>Lemons</th>\n",
       "      <th>thresh50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926557</td>\n",
       "      <td>0.073443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988686</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.983662</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.922047</td>\n",
       "      <td>0.077953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.782954</td>\n",
       "      <td>0.217046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Not_Lemons    Lemons  thresh50\n",
       "0    0.926557  0.073443         0\n",
       "1    0.988686  0.011314         0\n",
       "2    0.983662  0.016338         0\n",
       "3    0.922047  0.077953         0\n",
       "4    0.782954  0.217046         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# coefficients:\n",
    "logreg.coef_\n",
    "\n",
    "# predict class:\n",
    "lr_y_pred = logreg.predict(X_test)\n",
    "\n",
    "# predicted probability:\n",
    "lr_y_pp = pd.DataFrame(logreg.predict_proba(X_test), columns=[\"Not_Lemons\",\"Lemons\"])\n",
    "#output is probabiliyt for every y_pred. what \n",
    "\n",
    "lr_y_pp['thresh50'] = lr_y_pred\n",
    "lr_y_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('lemon_logreg2.pkl', 'w') as picklefile:\n",
    "#    pickle.dump(logreg, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     18856\n",
      "          1       0.25      0.00      0.00      1993\n",
      "\n",
      "avg / total       0.84      0.90      0.86     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,lr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold - 50%, 10%, 8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Not_Lemons    Lemons  thresh50  thresh10  thresh09  thresh08\n",
      "0    0.926557  0.073443         0         0         0         0\n",
      "1    0.988686  0.011314         0         0         0         0\n",
      "2    0.983662  0.016338         0         0         0         0\n",
      "3    0.922047  0.077953         0         0         0         0\n",
      "4    0.782954  0.217046         0         1         1         1\n",
      "5    0.894894  0.105106         0         1         0         1\n",
      "6    0.961769  0.038231         0         0         0         0\n",
      "7    0.836058  0.163942         0         1         1         1\n",
      "8    0.967147  0.032853         0         0         0         0\n",
      "9    0.948773  0.051227         0         0         0         0\n"
     ]
    }
   ],
   "source": [
    "lr_y_pp['thresh10'] = [1 if x >= 0.1 else 0 for x in lr_y_pp.Lemons.values]\n",
    "lr_y_pp['thresh09'] = [1 if x >= 0.12 else 0 for x in lr_y_pp.Lemons.values]\n",
    "lr_y_pp['thresh08'] = [1 if x >= 0.08 else 0 for x in lr_y_pp.Lemons.values]\n",
    "\n",
    "lr_pred10 = lr_y_pp['thresh10']\n",
    "lr_pred09 = lr_y_pp['thresh09']\n",
    "lr_pred08 = lr_y_pp['thresh08']\n",
    "\n",
    "print(lr_y_pp.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73917214254880326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_50 = accuracy_score(y_test, lr_y_pp['thresh09'])\n",
    "acc_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for 50% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon               2            1991\n",
      "Not_Lemon           6           18850 \n",
      "\n",
      "\n",
      "50% THRESHOLD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     18856\n",
      "          1       0.25      0.00      0.00      1993\n",
      "\n",
      "avg / total       0.84      0.90      0.86     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_conmat_50 = np.array(confusion_matrix(y_test, lr_y_pp.thresh50.values, labels=[1,0]))\n",
    "lr_confusion_50 = pd.DataFrame(lr_conmat_50, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "print \"Confusion Matrix for 50% threshold\" \"\\n\"\n",
    "print str(lr_confusion_50), \"\\n\" \"\\n\"\n",
    "\n",
    "print \"50% THRESHOLD\"\n",
    "print(classification_report(y_test,lr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10% Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65681807280924742"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_10 = accuracy_score(y_test, lr_y_pp['thresh1'])\n",
    "acc_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for 10% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon            1224             769\n",
      "Not_Lemon        6386           12470 \n",
      "\n",
      "\n",
      "10% THRESHOLD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.66      0.78     18856\n",
      "          1       0.16      0.61      0.25      1993\n",
      "\n",
      "avg / total       0.87      0.66      0.73     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_conmat_10 = np.array(confusion_matrix(y_test, lr_y_pp.thresh10.values, labels=[1,0]))\n",
    "lr_confusion_10 = pd.DataFrame(lr_conmat_10, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "print \"Confusion Matrix for 10% threshold\" \"\\n\"\n",
    "print str(lr_confusion_10), \"\\n\" \"\\n\"\n",
    "\n",
    "print \"10% THRESHOLD\"\n",
    "print(classification_report(y_test,lr_pred10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12% Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for 12% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon            1016             977\n",
      "Not_Lemon        4461           14395 \n",
      "\n",
      "\n",
      "12% THRESHOLD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.76      0.84     18856\n",
      "          1       0.19      0.51      0.27      1993\n",
      "\n",
      "avg / total       0.86      0.74      0.79     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_conmat_09 = np.array(confusion_matrix(y_test, lr_y_pp.thresh09.values, labels=[1,0]))\n",
    "lr_confusion_09 = pd.DataFrame(lr_conmat_09, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "print \"Confusion Matrix for 12% threshold\" \"\\n\"\n",
    "print str(lr_confusion_09), \"\\n\" \"\\n\"\n",
    "\n",
    "print \"12% THRESHOLD\"\n",
    "print(classification_report(y_test,lr_pred09))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7391721425488033"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total =  1016 + 977 + 4461 + 14395\n",
    "correct = 1016 + 14395\n",
    "acc = float(correct) / total\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8% Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for 8% threshold\n",
      "\n",
      "           pred_lemon  pred_not_lemon\n",
      "Lemon            1016             977\n",
      "Not_Lemon        4461           14395 \n",
      "\n",
      "\n",
      "8% THRESHOLD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.52      0.67     18856\n",
      "          1       0.14      0.74      0.24      1993\n",
      "\n",
      "avg / total       0.87      0.54      0.63     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_conmat_08 = np.array(confusion_matrix(y_test, lr_y_pp.thresh08.values, labels=[1,0]))\n",
    "lr_confusion_08 = pd.DataFrame(lr_conmat_08, index=['Lemon', 'Not_Lemon'],columns=['pred_lemon','pred_not_lemon'])\n",
    "\n",
    "print \"Confusion Matrix for 8% threshold\" \"\\n\"\n",
    "print str(lr_confusion_09), \"\\n\" \"\\n\"\n",
    "\n",
    "print \"8% THRESHOLD\"\n",
    "print(classification_report(y_test,lr_pred08))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model 4: ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "ada_predictions = ada.predict(X_test)\n",
    "\n",
    "# predicted probability:\n",
    "ada_y_pp = pd.DataFrame(ada.predict_proba(X_test), columns=[\"Not_Lemons\",\"Lemons\"])\n",
    "\n",
    "ada_y_pp['thresh50'] = ada_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Not_Lemons    Lemons  thresh50  thresh45  thresh40\n",
      "0    0.512122  0.487878         0         1         1\n",
      "1    0.524159  0.475841         0         1         1\n",
      "2    0.518706  0.481294         0         1         1\n",
      "3    0.513232  0.486768         0         1         1\n",
      "4    0.507843  0.492157         0         1         1\n",
      "5    0.508453  0.491547         0         1         1\n",
      "6    0.515313  0.484687         0         1         1\n",
      "7    0.507047  0.492953         0         1         1\n",
      "8    0.517075  0.482925         0         1         1\n",
      "9    0.513652  0.486348         0         1         1\n"
     ]
    }
   ],
   "source": [
    "ada_y_pp['thresh45'] = [1 if x >= 0.45 else 0 for x in ada_y_pp.Lemons.values]\n",
    "ada_y_pp['thresh40'] = [1 if x >= 0.4 else 0 for x in ada_y_pp.Lemons.values]\n",
    "\n",
    "print(ada_y_pp.iloc[0:10])\n",
    "\n",
    "ada_pred45 = ada_y_pp['thresh45']\n",
    "ada_pred40 = ada_y_pp['thresh40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     18856\n",
      "          1       0.50      0.00      0.00      1993\n",
      "\n",
      "avg / total       0.87      0.90      0.86     20849\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.00      0.00     18856\n",
      "          1       0.10      1.00      0.17      1993\n",
      "\n",
      "avg / total       0.84      0.10      0.02     20849\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.00      0.00     18856\n",
      "          1       0.10      1.00      0.17      1993\n",
      "\n",
      "avg / total       0.84      0.10      0.02     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ada_predictions))\n",
    "print(classification_report(y_test,ada_pred45))\n",
    "print(classification_report(y_test,ada_pred40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINDINGS: ADA\n",
    "* ada is not performing well.\n",
    "* probabilites are closer together since the machine is learning from incorrectly labeled targets from previous iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "0.524606258168\n"
     ]
    }
   ],
   "source": [
    "ada_PARAMETERS = {\"base_estimator__max_depth\":[1,2,3,4,5,7,9,10,15,20],\"n_estimators\":[30,50,70] }\n",
    "\n",
    "DTC = DecisionTreeClassifier()\n",
    "ada_SCORING = \"precision\"\n",
    "ABC = AdaBoostClassifier(base_estimator = DTC)\n",
    "\n",
    "grid = GridSearchCV(ABC, param_grid=ada_PARAMETERS, scoring=ada_SCORING)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print grid.best_estimator_\n",
    "print grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=1))\n",
    "ada.fit(X_train, y_train)\n",
    "ada_predictions = ada.predict(X_test)\n",
    "\n",
    "# predicted probability:\n",
    "ada_y_pp = pd.DataFrame(ada.predict_proba(X_test), columns=[\"Not_Lemons\",\"Lemons\"])\n",
    "\n",
    "ada_y_pp['thresh50'] = ada_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Not_Lemons    Lemons  thresh50  thresh45  thresh40\n",
      "0    0.512535  0.487465         0         1         1\n",
      "1    0.524415  0.475585         0         1         1\n",
      "2    0.520084  0.479916         0         1         1\n",
      "3    0.511712  0.488288         0         1         1\n",
      "4    0.506790  0.493210         0         1         1\n",
      "5    0.509438  0.490562         0         1         1\n",
      "6    0.514876  0.485124         0         1         1\n",
      "7    0.507741  0.492259         0         1         1\n",
      "8    0.517538  0.482462         0         1         1\n",
      "9    0.514057  0.485943         0         1         1\n"
     ]
    }
   ],
   "source": [
    "ada_y_pp['thresh45'] = [1 if x >= 0.45 else 0 for x in ada_y_pp.Lemons.values]\n",
    "ada_y_pp['thresh40'] = [1 if x >= 0.4 else 0 for x in ada_y_pp.Lemons.values]\n",
    "\n",
    "print(ada_y_pp.iloc[0:10])\n",
    "\n",
    "ada_pred45 = ada_y_pp['thresh45']\n",
    "ada_pred40 = ada_y_pp['thresh40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     18856\n",
      "          1       0.44      0.00      0.01      1993\n",
      "\n",
      "avg / total       0.86      0.90      0.86     20849\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.00      0.00     18856\n",
      "          1       0.10      1.00      0.17      1993\n",
      "\n",
      "avg / total       0.84      0.10      0.02     20849\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.00      0.00     18856\n",
      "          1       0.10      1.00      0.17      1993\n",
      "\n",
      "avg / total       0.84      0.10      0.02     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ada_predictions))\n",
    "print(classification_report(y_test,ada_pred45))\n",
    "print(classification_report(y_test,ada_pred40))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model 5 : Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.3)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_predictions = gb.predict(X_test)\n",
    "# predicted probability:\n",
    "gb_y_pp = pd.DataFrame(gb.predict_proba(X_test), columns=[\"Not_Lemons\",\"Lemons\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_y_pp['thresh50'] = gb_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Not_Lemons    Lemons  thresh50  thresh10  thresh11\n",
      "0    0.920413  0.079587         0         0         0\n",
      "1    0.985552  0.014448         0         0         0\n",
      "2    0.893736  0.106264         0         1         0\n",
      "3    0.886354  0.113646         0         1         1\n",
      "4    0.882154  0.117846         0         1         1\n",
      "5    0.892576  0.107424         0         1         0\n",
      "6    0.922133  0.077867         0         0         0\n",
      "7    0.817917  0.182083         0         1         1\n",
      "8    0.954117  0.045883         0         0         0\n",
      "9    0.954655  0.045345         0         0         0\n"
     ]
    }
   ],
   "source": [
    "gb_y_pp['thresh10'] = [1 if x >= 0.1 else 0 for x in gb_y_pp.Lemons.values]\n",
    "gb_y_pp['thresh11'] = [1 if x >= 0.11 else 0 for x in gb_y_pp.Lemons.values]\n",
    "\n",
    "print(gb_y_pp.iloc[0:10])\n",
    "\n",
    "gb_pred10 = gb_y_pp['thresh10']\n",
    "gb_pred08 = gb_y_pp['thresh11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95     18856\n",
      "          1       0.23      0.01      0.02      1993\n",
      "\n",
      "avg / total       0.84      0.90      0.86     20849\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.70      0.80     18856\n",
      "          1       0.17      0.59      0.26      1993\n",
      "\n",
      "avg / total       0.87      0.69      0.75     20849\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.75      0.83     18856\n",
      "          1       0.18      0.52      0.27      1993\n",
      "\n",
      "avg / total       0.86      0.73      0.78     20849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,gb_predictions))\n",
    "print(classification_report(y_test,gb_pred10))\n",
    "print(classification_report(y_test,gb_pred08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14095  4761]\n",
      " [  954  1039]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,gb_pred08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69415541369762346"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, y_score)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69415541369762346"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
